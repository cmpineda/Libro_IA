{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo Modelo Seq2Seq Sin atención"
      ],
      "metadata": {
        "id": "C9ydyrdHpjBY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "3Co6KBHcz0ck"
      },
      "outputs": [],
      "source": [
        "def quitarchar(texto):\n",
        "  texto = texto.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "  return texto.strip()\n",
        "\n",
        "with open('spa.txt','r',encoding='utf8') as f:\n",
        "  datos=[(quitarchar(x.split('\\t')[0]),quitarchar(x.split('\\t')[1])) for x in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkL9D99U0TJP",
        "outputId": "3b39301d-af87-4e4b-d46b-64281a786303"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Go.', 'Ve.'),\n",
              " ('Go.', 'Vete.'),\n",
              " ('Go.', 'Vaya.'),\n",
              " ('Go.', 'Váyase.'),\n",
              " ('Hi.', 'Hola.'),\n",
              " ('Run!', 'Corre!'),\n",
              " ('Run!', 'Corran!'),\n",
              " ('Run!', 'Huye!'),\n",
              " ('Run!', 'Corra!'),\n",
              " ('Run!', 'Corred!')]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.shuffle(datos)\n",
        "palabras_ingles, palabras_español = zip(*datos)\n",
        "long_vocab_ingles = len(palabras_ingles)\n",
        "long_vocab_español = len(palabras_español)"
      ],
      "metadata": {
        "id": "4q9SsTpk0hVv"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Longitud Vocab Español: {long_vocab_ingles}')\n",
        "print(f'Logitud Vocab Inglés: {long_vocab_español}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52RZivBLzGJz",
        "outputId": "faaf57f9-7478-4a7f-f0a1-1946ab10dfab"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud Vocab Español: 141543\n",
            "Logitud Vocab Inglés: 141543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(palabras_ingles[i], \"=>\", palabras_español[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jtW9ZvS0l0e",
        "outputId": "fa188cef-0c70-4724-bb27-27aac675c1c3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm single again. => Estoy solo otra vez.\n",
            "Don't leave your belongings unattended at the beach. => No dejes tus pertenencias desatendidas en el playa.\n",
            "You're joking, aren't you? => Estás bromeando, verdad?\n",
            "Why take a chance? => Para qué correr el riesgo?\n",
            "There are many more students in the classroom today than yesterday. => Hoy hay muchos más estudiantes en la sala que ayer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "long_ing_max = max(len(linea.split()) for linea in palabras_ingles)\n",
        "long_esp_max = max(len(linea.split()) for linea in palabras_español)\n",
        "long_secuencia = max(long_ing_max, long_esp_max)\n",
        "\n",
        "print(f'Max Longitud Frases en Inglés: {long_ing_max}')\n",
        "print(f'Max Longitud Frases en Español: {long_esp_max}')\n",
        "print(f'Logitud de la secuencia: {long_secuencia}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvGqjInFtp_P",
        "outputId": "fbb6f082-322d-433e-b7f8-f9e5971aedce"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Longitud Frases en Inglés: 70\n",
            "Max Longitud Frases en Español: 68\n",
            "Logitud de la secuencia: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "tam_voc = 1000\n",
        "long_max = 70\n",
        "capa_vect_ing = tf.keras.layers.TextVectorization(\n",
        "    tam_voc, output_sequence_length=long_max)\n",
        "capa_vect_esp = tf.keras.layers.TextVectorization(\n",
        "    tam_voc, output_sequence_length=long_max)\n",
        "capa_vect_ing.adapt(palabras_ingles)\n",
        "capa_vect_esp.adapt([f\"startseq {s} endseq\" for s in palabras_español])"
      ],
      "metadata": {
        "id": "7EzLcdBe0yK7"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Inglés:\")\n",
        "print(capa_vect_ing.get_vocabulary()[:10])\n",
        "\n",
        "print(\"\\nEspañol:\")\n",
        "print(capa_vect_esp.get_vocabulary()[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4gsr8EZ03h3",
        "outputId": "aeeb89f4-3f39-4a6a-cc26-0112fe9b4502"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inglés:\n",
            "['', '[UNK]', 'i', 'the', 'to', 'you', 'tom', 'a', 'is', 'he']\n",
            "\n",
            "Español:\n",
            "['', '[UNK]', 'startseq', 'endseq', 'de', 'que', 'no', 'tom', 'a', 'la']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.constant(palabras_ingles[:120_000])\n",
        "X_valid = tf.constant(palabras_ingles[120_000:])\n",
        "X_train_dec = tf.constant([f\"startseq {s}\" for s in palabras_español[:120_000]])\n",
        "X_valid_dec = tf.constant([f\"startseq {s}\" for s in palabras_español[120_000:]])\n",
        "Y_train = capa_vect_esp([f\"{s} endseq\" for s in palabras_español[:120_000]])\n",
        "Y_valid = capa_vect_esp([f\"{s} endseq\" for s in palabras_español[120_000:]])"
      ],
      "metadata": {
        "id": "bXYHFdu-08wi"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ent_cod = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "ent_dec = tf.keras.layers.Input(shape=[], dtype=tf.string)"
      ],
      "metadata": {
        "id": "PTbMXAFP1Bg9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tam_emb = 128\n",
        "ids_ent_cod = capa_vect_ing(ent_cod)\n",
        "ids_ent_dec = capa_vect_esp(ent_dec)\n",
        "\n",
        "capa_embedding_cod = tf.keras.layers.Embedding(tam_voc, tam_emb,\n",
        "                                                    mask_zero=True)\n",
        "capa_embedding_dec = tf.keras.layers.Embedding(tam_voc, tam_emb,\n",
        "                                                    mask_zero=True)\n",
        "embeddings_cod = capa_embedding_cod(ids_ent_cod)\n",
        "embeddings_dec = capa_embedding_dec(ids_ent_dec)"
      ],
      "metadata": {
        "id": "6N8w1MeN1Egw"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creamos el codificador\n",
        "codificador = tf.keras.layers.LSTM(512, return_state=True)\n",
        "salidas_cod, *estado_cod = codificador(embeddings_cod)"
      ],
      "metadata": {
        "id": "w3XUYYGW1FbW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creamos el decodificador\n",
        "decodificador = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "salidas_dec = decodificador(embeddings_dec, initial_state=estado_cod)"
      ],
      "metadata": {
        "id": "yGRCh5mM1L27"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capa_salida = tf.keras.layers.Dense(tam_voc, activation=\"softmax\")\n",
        "Y_proba = capa_salida(salidas_dec)"
      ],
      "metadata": {
        "id": "GkPwmrH81O0I"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = tf.keras.Model(inputs=[ent_cod, ent_dec],\n",
        "                       outputs=[Y_proba])\n",
        "modelo.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "modelo.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "lQLEAglW1XLW",
        "outputId": "d967c3ac-2876-4d7b-8d50-d97ce9fe17f1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6             │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_7             │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m128,000\u001b[0m │ text_vectorization_6[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_6 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ text_vectorization_6[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m128,000\u001b[0m │ text_vectorization_7[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │      \u001b[38;5;34m1,312,768\u001b[0m │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]     │                │ not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m1,312,768\u001b[0m │ embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n",
              "│                           │                        │                │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │        \u001b[38;5;34m513,000\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text_vectorization_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)       │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ text_vectorization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_vectorization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ text_vectorization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]     │                │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          │\n",
              "│                           │                        │                │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">513,000</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,394,536\u001b[0m (12.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,394,536</span> (12.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,394,536\u001b[0m (12.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,394,536</span> (12.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.fit((X_train, X_train_dec), Y_train, epochs=5,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H3Ney4m2Fyy",
        "outputId": "a7cec51a-abe5-4635-883f-c4a3d19a5198"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 27ms/step - accuracy: 0.0375 - loss: 3.4009 - val_accuracy: 0.0549 - val_loss: 2.0048\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 27ms/step - accuracy: 0.0576 - loss: 1.8417 - val_accuracy: 0.0633 - val_loss: 1.5206\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 27ms/step - accuracy: 0.0658 - loss: 1.3808 - val_accuracy: 0.0665 - val_loss: 1.3532\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 28ms/step - accuracy: 0.0707 - loss: 1.1399 - val_accuracy: 0.0678 - val_loss: 1.2969\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 28ms/step - accuracy: 0.0742 - loss: 0.9726 - val_accuracy: 0.0682 - val_loss: 1.2909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e600d3beb60>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def traducir(oracion_ingles):\n",
        "    traduccion = \"\"\n",
        "    for id_palabra in range(long_max):\n",
        "        X = tf.constant([oracion_ingles])  # codificar entrada\n",
        "        X_dec = tf.constant([\"startseq \" + traduccion])  # decodificar entrada\n",
        "        y_proba = modelo.predict((X, X_dec))[0, id_palabra]  # probabilidad del último token\n",
        "        id_palabra_predicha = np.argmax(y_proba)\n",
        "        palabra_predicha = capa_vect_esp.get_vocabulary()[id_palabra_predicha]\n",
        "        if palabra_predicha == \"endseq\":\n",
        "            break\n",
        "        traduccion += \" \" + palabra_predicha\n",
        "    return traduccion.strip()"
      ],
      "metadata": {
        "id": "1KdiPWn12Liw"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traducir(\"I like soccer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "7QQqcsjM3UrG",
        "outputId": "fbfb8f10-d49d-41ff-d9b3-eb3a4b895a08"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta el fútbol'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dG6zE0YM4MX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo Modelo Seq2Seq con atención"
      ],
      "metadata": {
        "id": "nJIZoEOLpomw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Usamos una capa Bidireccional para el codificador\n",
        "codificador = tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True, return_state=True))"
      ],
      "metadata": {
        "id": "JzN22Omp8-ut"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrate de que salidas_cod tenga la forma adecuada\n",
        "salidas_cod_exp = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.expand_dims(x, axis=1),  # Expande para tener una dimensión de secuencia\n",
        "    output_shape=(1, salidas_cod.shape[-1])  # Define la forma de salida\n",
        ")(salidas_cod)\n",
        "\n",
        "salidas_dec_exp = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.expand_dims(x, axis=1),\n",
        "    output_shape=(1, salidas_dec.shape[-1])\n",
        ")(salidas_dec)\n",
        "\n",
        "# Capa de atención\n",
        "capa_atencion = tf.keras.layers.Attention()\n",
        "\n",
        "# Calcula la salida de atención\n",
        "salida_atencion = capa_atencion([salidas_dec_exp, salidas_cod_exp])\n",
        "\n",
        "# Agrega la capa de salida\n",
        "capa_salida = tf.keras.layers.Dense(tam_voc, activation=\"softmax\")\n",
        "Y_proba = capa_salida(salida_atencion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfOFSLK0p2_B",
        "outputId": "878f197a-a8be-4a12-e1bb-3e8ad8c860fb"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'lambda_16' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traducir(\"I like play soccer with my friends\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "f9sXoaopqSna",
        "outputId": "19a1f7d8-8dff-4f8f-8d96-716ba7ae560c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta jugar al tenis con mis amigos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo Modelo con Transformer"
      ],
      "metadata": {
        "id": "d61GJUrBDrZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "Ef-pnAfGFlNS"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_max = 70  # maxima longitud de palabra\n",
        "tam_emb = 128\n",
        "tf.random.set_seed(42)\n",
        "pos_capa_emb = tf.keras.layers.Embedding(long_max, tam_emb)\n",
        "max_long_lote_cod = tf.keras.backend.int_shape(embeddings_cod)[1]\n",
        "\n",
        "ent_codif = embeddings_cod + pos_capa_emb(tf.range(max_long_lote_cod))\n",
        "max_long_lote_dec = tf.keras.backend.int_shape(embeddings_dec)[1]\n",
        "\n",
        "ent_decodif = embeddings_cod + pos_capa_emb(tf.range(max_long_lote_dec))"
      ],
      "metadata": {
        "id": "UXB0TNWjOHJo"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones auxiliares para codificación posicional\n",
        "def obtener_angulos(pos, i, d_model):\n",
        "    angulos = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angulos\n",
        "\n",
        "def codificacion_posicional(posicion, d_model):\n",
        "    radianes = obtener_angulos(np.arange(posicion)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
        "    radianes[:, 0::2] = np.sin(radianes[:, 0::2])\n",
        "    radianes[:, 1::2] = np.cos(radianes[:, 1::2])\n",
        "    pos_codificacion = radianes[np.newaxis, ...]\n",
        "    return tf.cast(pos_codificacion, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "A4kEFM97BdjA"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d_model = 128\n",
        "entradas = Input(shape=(None,))\n",
        "etiquetas = Input(shape=(None,))\n",
        "\n",
        "# Embedding y codificación posicional para el codificador\n",
        "cod_pos_cod = codificacion_posicional(long_max, tam_emb)\n",
        "embeddings_cod += cod_pos_cod[:tf.keras.backend.int_shape(embeddings_cod)[1], :]\n",
        "\n",
        "# Embedding y codificación posicional para el decodificador\n",
        "dec_pos_encoding = codificacion_posicional(long_max, tam_emb)\n",
        "embeddings_dec += dec_pos_encoding[:tf.keras.backend.int_shape(embeddings_dec)[1], :]"
      ],
      "metadata": {
        "id": "DGUrP_3JCLXA"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Codificador\n",
        "N = 2\n",
        "num_cabezas = 8\n",
        "tasa_dropout = 0.1\n",
        "n_unidades = 128\n",
        "\n",
        "# se encapsula la operación en una capa landa que es compatible con un modelo simbólica\n",
        "masc_cod = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.math.not_equal(x, 0)[:, tf.newaxis]\n",
        ")(ids_ent_cod)\n",
        "\n",
        "Z = embeddings_cod\n",
        "for _ in range(N):\n",
        "    salto = Z\n",
        "    capa_atencion = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_cabezas, key_dim=tam_emb, dropout=tasa_dropout)\n",
        "    Z = capa_atencion(Z, value=Z, attention_mask=masc_cod)\n",
        "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, salto]))\n",
        "    salto = Z\n",
        "    Z = tf.keras.layers.Dense(n_unidades, activation=\"relu\")(Z)\n",
        "    Z = tf.keras.layers.Dense(tam_emb)(Z)\n",
        "    Z = tf.keras.layers.Dropout(tasa_dropout)(Z)\n",
        "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, salto]))"
      ],
      "metadata": {
        "id": "MlAgXm86PEIR"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder_pad_mask = tf.math.not_equal(decoder_input_ids, 0)[:, tf.newaxis]\n",
        "masc_dec = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.math.not_equal(x, 0)[:, tf.newaxis]\n",
        ")(ids_ent_dec)\n",
        "\n",
        "causal_mask = tf.linalg.band_part(  # Matriz triangular inferior\n",
        "    tf.ones((max_long_lote_dec, max_long_lote_cod), tf.bool), -1, 0)"
      ],
      "metadata": {
        "id": "H1byr1KOP9nH"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decodificador\n",
        "salida_cod = Z  # Se almacena la salida final de codificador\n",
        "Z = embeddings_dec  # El decodificador inicar con su entrada propia\n",
        "for _ in range(N):\n",
        "    salto = Z\n",
        "    capa_atencion = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_cabezas, key_dim=tam_emb, dropout=tasa_dropout)\n",
        "    Z = capa_atencion(Z, value=Z, attention_mask=causal_mask & masc_dec)\n",
        "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, salto]))\n",
        "    salto = Z\n",
        "    capa_atencion = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_cabezas, key_dim=tam_emb, dropout=tasa_dropout)\n",
        "    Z = capa_atencion(Z, value=salida_cod, attention_mask=masc_cod)\n",
        "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, salto]))\n",
        "    salto = Z\n",
        "    Z = tf.keras.layers.Dense(n_unidades, activation=\"relu\")(Z)\n",
        "    Z = tf.keras.layers.Dense(tam_emb)(Z)\n",
        "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, salto]))"
      ],
      "metadata": {
        "id": "X4M6oXSxQDDn"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_proba = tf.keras.layers.Dense(tam_voc, activation=\"softmax\")(Z)\n",
        "modelo = tf.keras.Model(inputs=[ent_cod, ent_dec],\n",
        "                       outputs=[Y_proba])\n",
        "modelo.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "eqyQbzfIQIjC"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LqY0PAZQKj_",
        "outputId": "09abcb29-7b68-45fd-cebe-66c5488787b4"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 69ms/step - accuracy: 0.9402 - loss: 0.3696 - val_accuracy: 0.9641 - val_loss: 0.1562\n",
            "Epoch 2/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 69ms/step - accuracy: 0.9646 - loss: 0.1531 - val_accuracy: 0.9681 - val_loss: 0.1339\n",
            "Epoch 3/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 69ms/step - accuracy: 0.9678 - loss: 0.1344 - val_accuracy: 0.9695 - val_loss: 0.1269\n",
            "Epoch 4/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 70ms/step - accuracy: 0.9694 - loss: 0.1250 - val_accuracy: 0.9707 - val_loss: 0.1212\n",
            "Epoch 5/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 69ms/step - accuracy: 0.9706 - loss: 0.1186 - val_accuracy: 0.9711 - val_loss: 0.1176\n",
            "Epoch 6/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 71ms/step - accuracy: 0.9715 - loss: 0.1136 - val_accuracy: 0.9720 - val_loss: 0.1138\n",
            "Epoch 7/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 69ms/step - accuracy: 0.9721 - loss: 0.1101 - val_accuracy: 0.9725 - val_loss: 0.1121\n",
            "Epoch 8/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 69ms/step - accuracy: 0.9727 - loss: 0.1067 - val_accuracy: 0.9728 - val_loss: 0.1109\n",
            "Epoch 9/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 69ms/step - accuracy: 0.9733 - loss: 0.1040 - val_accuracy: 0.9731 - val_loss: 0.1095\n",
            "Epoch 10/10\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 69ms/step - accuracy: 0.9737 - loss: 0.1021 - val_accuracy: 0.9733 - val_loss: 0.1089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e5fddf6dae0>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traducir(\"I like soccer and studying at home\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "AeMR_vdVjrMg",
        "outputId": "ee8c4a6b-a33b-4bf8-ed54-2f44b70942c6"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta el fútbol y estudiar en casa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7Uzsq2o4Nxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OmtjQv4dKphL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}